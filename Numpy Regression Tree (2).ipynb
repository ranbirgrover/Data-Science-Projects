{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23210700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data wrangling \n",
    "import pandas as pd \n",
    "\n",
    "# Array math\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "class NodeRegression():\n",
    "    \"\"\"\n",
    "    Class to grow a regression decision tree\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        Y: list,\n",
    "        X: pd.DataFrame,\n",
    "        min_samples_split=None,\n",
    "        max_depth=None,\n",
    "        depth=None,\n",
    "        node_type=None,\n",
    "        rule=None\n",
    "    ):\n",
    "    \n",
    "        self.Y = Y \n",
    "        self.X = X\n",
    "\n",
    "        self.min_samples_split = min_samples_split if min_samples_split else 20\n",
    "        self.max_depth = max_depth if max_depth else 5\n",
    "\n",
    "        self.depth = depth if depth else 0\n",
    "\n",
    "        self.features = list(self.X.columns)\n",
    "\n",
    "    \n",
    "        self.node_type = node_type if node_type else 'root'\n",
    "\n",
    "        self.rule = rule if rule else \"\" \n",
    "\n",
    "    \n",
    "        self.ymean = np.mean(Y)\n",
    "\n",
    "        # Getting the residuals \n",
    "        self.residuals = self.Y - self.ymean\n",
    "\n",
    "        # Calculating the mse of the node \n",
    "        self.mse = self.get_mse(Y, self.ymean)\n",
    "\n",
    "        # Saving the number of observations in the node \n",
    "        self.n = len(Y)\n",
    "\n",
    "        # Initiating the left and right nodes as empty nodes\n",
    "        self.left = None \n",
    "        self.right = None \n",
    "\n",
    "        # Default values for splits\n",
    "        self.best_feature = None \n",
    "        self.best_value = None \n",
    "\n",
    "        \n",
    "    def get_mse(self, y_true, y_pred) -> float:\n",
    "        \"\"\"\n",
    "        Method to calculate the mean squared error \n",
    "        \"\"\"\n",
    "        return np.mean((y_true - y_pred) ** 2)\n",
    "    \n",
    "    # X = [1,2,3,4]\n",
    "    # window  = 2\n",
    "    #out = [1.5,2.5,3.5]\n",
    "\n",
    "    def ma(self, x: np.array, window: int) -> np.array:\n",
    "        \"\"\"\n",
    "        Calculates the moving average of the given list. \n",
    "        \"\"\"\n",
    "        return np.convolve(x, np.ones(window), 'valid') / window\n",
    "\n",
    "    def best_split(self) -> tuple:\n",
    "        \"\"\"\n",
    "        Given the X features and Y targets calculates the best split \n",
    "        for a decision tree\n",
    "        \"\"\"\n",
    "        # Creating a dataset for spliting\n",
    "        df = self.X.copy()\n",
    "        df['Y'] = self.Y\n",
    "\n",
    "        # Getting the GINI impurity for the base input \n",
    "        mse_base = self.mse\n",
    "\n",
    "        # Finding which split yields the best GINI gain \n",
    "        #max_gain = 0\n",
    "\n",
    "        # Default best feature and split\n",
    "        best_feature = None\n",
    "        best_value = None\n",
    "\n",
    "        for feature in self.features:\n",
    "            # Droping missing values\n",
    "            Xdf = df.dropna().sort_values(feature)\n",
    "\n",
    "            # Sorting the values and getting the rolling average\n",
    "            xmeans = self.ma(Xdf[feature].unique(), 2)\n",
    "\n",
    "            for value in xmeans:\n",
    "                # Getting the left and right ys \n",
    "                left_y = Xdf[Xdf[feature]<value]['Y'].values\n",
    "                right_y = Xdf[Xdf[feature]>=value]['Y'].values\n",
    "\n",
    "                # Getting the means \n",
    "                left_mean = np.mean(left_y)\n",
    "                right_mean = np.mean(right_y)\n",
    "\n",
    "                # Getting the left and right residuals \n",
    "                res_left = left_y - left_mean \n",
    "                res_right = right_y - right_mean\n",
    "\n",
    "                # Concatenating the residuals \n",
    "                r = np.concatenate((res_left, res_right), axis=None)\n",
    "\n",
    "                # Calculating the mse \n",
    "                n = len(r)\n",
    "                r = r ** 2\n",
    "                r = np.sum(r)\n",
    "                mse_split = r / n\n",
    "\n",
    "                # Checking if this is the best split so far \n",
    "                if mse_split < mse_base:\n",
    "                    best_feature = feature\n",
    "                    best_value = value \n",
    "\n",
    "                    # Setting the best gain to the current one \n",
    "                    mse_base = mse_split\n",
    "\n",
    "        return (best_feature, best_value)\n",
    "    \n",
    "    \n",
    "    # Growing tree recursively\n",
    "    def grow_tree(self):\n",
    "        \"\"\"\n",
    "        Recursive method to create the decision tree\n",
    "        \"\"\"\n",
    "        # Making a df from the data \n",
    "        df = self.X.copy()\n",
    "        df['Y'] = self.Y\n",
    "\n",
    "        # If there is GINI to be gained, we split further \n",
    "        if (self.depth < self.max_depth) and (self.n >= self.min_samples_split):\n",
    "\n",
    "            # Getting the best split \n",
    "            best_feature, best_value = self.best_split()\n",
    "\n",
    "            if best_feature is not None:\n",
    "                # Saving the best split to the current node \n",
    "                self.best_feature = best_feature\n",
    "                self.best_value = best_value\n",
    "\n",
    "                # Getting the left and right nodes\n",
    "                left_df, right_df = df[df[best_feature]<=best_value].copy(), df[df[best_feature]>best_value].copy()\n",
    "\n",
    "                # Creating the left and right nodes\n",
    "                left = NodeRegression(\n",
    "                    left_df['Y'].values.tolist(), \n",
    "                    left_df[self.features], \n",
    "                    depth=self.depth + 1, \n",
    "                    max_depth=self.max_depth, \n",
    "                    min_samples_split=self.min_samples_split, \n",
    "                    node_type='left_node',\n",
    "                    rule=f\"{best_feature} <= {round(best_value, 3)}\"\n",
    "                    )\n",
    "\n",
    "                self.left = left \n",
    "                self.left.grow_tree()\n",
    "\n",
    "                right = NodeRegression(\n",
    "                    right_df['Y'].values.tolist(), \n",
    "                    right_df[self.features], \n",
    "                    depth=self.depth + 1, \n",
    "                    max_depth=self.max_depth, \n",
    "                    min_samples_split=self.min_samples_split,\n",
    "                    node_type='right_node',\n",
    "                    rule=f\"{best_feature} > {round(best_value, 3)}\"\n",
    "                    )\n",
    "\n",
    "                self.right = right\n",
    "                self.right.grow_tree()\n",
    "\n",
    "    def print_info(self, width=4):\n",
    "        \"\"\"\n",
    "        Method to print the infromation about the tree\n",
    "        \"\"\"\n",
    "        # Defining the number of spaces \n",
    "        const = int(self.depth * width ** 1.5)\n",
    "        spaces = \"-\" * const\n",
    "        \n",
    "        if self.node_type == 'root':\n",
    "            print(\"Root\")\n",
    "        else:\n",
    "            print(f\"|{spaces} Split rule: {self.rule}\")\n",
    "        print(f\"{' ' * const}   | MSE of the node: {round(self.mse, 2)}\")\n",
    "        print(f\"{' ' * const}   | Count of observations in node: {self.n}\")\n",
    "        print(f\"{' ' * const}   | Prediction of node: {round(self.ymean, 3)}\")   \n",
    "\n",
    "    \n",
    "    # Displaying the tree structure\n",
    "    def print_tree(self):\n",
    "        \"\"\"\n",
    "        Prints the whole tree from the current node to the bottom\n",
    "        \"\"\"\n",
    "        self.print_info() \n",
    "        \n",
    "        if self.left is not None: \n",
    "            self.left.print_tree()\n",
    "        \n",
    "        if self.right is not None:\n",
    "            self.right.print_tree()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "345ea467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Train test split with shuffle as true\n",
    "\n",
    "def shuffle_data(X, y, seed=None):\n",
    "    \"\"\" Random shuffle of the samples in X and y \"\"\"\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "    idx = np.arange(X.shape[0])\n",
    "    np.random.shuffle(idx)\n",
    "    try:\n",
    "        return X[idx], y[idx]\n",
    "    except:\n",
    "        return X.iloc[idx], y.iloc[idx]\n",
    "    \n",
    "    \n",
    "def train_test_split(X, y, test_size=0.5, shuffle=True, seed=None):\n",
    "    \"\"\" Split the data into train and test sets \"\"\"\n",
    "    if shuffle:\n",
    "        X, y = shuffle_data(X, y, seed)\n",
    "    # Split the training data from test data in the ratio specified in\n",
    "    # test_size\n",
    "    split_i = len(y) - int(len(y) // (1 / test_size))\n",
    "    X_train, X_test = X[:split_i], X[split_i:]\n",
    "    y_train, y_test = y[:split_i], y[split_i:]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2e6cedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"EPL_Soccer_MLR_LR.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "df.dropna(axis=0, how='all', thresh=None, subset=None, inplace=True)\n",
    "\n",
    "\n",
    "new_df = df.select_dtypes(['number'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbec9db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_df = df.select_dtypes(['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5be6876",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = new_df.iloc[:,:-1]\n",
    "y = new_df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "301b4767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6289deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculation of Correlated Matrix\n",
    "correlated_features = set()\n",
    "correlation_matrix = X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "845b1d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Height', 'MinutestoGoalRatio', 'ShotsPerGame', 'Weight'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.8:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_features.add(colname)\n",
    "            \n",
    "correlated_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "214e4f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Goutam Kelam\\miniconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "# Dropping correlated features\n",
    "X_train.drop(columns=correlated_features, axis=1, inplace=True)\n",
    "X_test.drop(columns=correlated_features, axis=1, inplace=True)\n",
    "X.drop(columns=correlated_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b7d9bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of root node\n",
    "root = NodeRegression(y_train, X_train, max_depth=2, min_samples_split=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1df531a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.NodeRegression at 0x1ea0c2d9ee0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1db8135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# growing the tree recursively\n",
    "root.grow_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42061113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root\n",
      "   | MSE of the node: 35.87\n",
      "   | Count of observations in node: 162\n",
      "   | Prediction of node: 13.587\n",
      "|-------- Split rule: Cost <= 68.05\n",
      "           | MSE of the node: 5.33\n",
      "           | Count of observations in node: 93\n",
      "           | Prediction of node: 9.187\n",
      "|---------------- Split rule: Cost <= 44.65\n",
      "                   | MSE of the node: 1.8\n",
      "                   | Count of observations in node: 44\n",
      "                   | Prediction of node: 7.431\n",
      "|---------------- Split rule: Cost > 44.65\n",
      "                   | MSE of the node: 3.24\n",
      "                   | Count of observations in node: 49\n",
      "                   | Prediction of node: 10.764\n",
      "|-------- Split rule: Cost > 68.05\n",
      "           | MSE of the node: 15.78\n",
      "           | Count of observations in node: 69\n",
      "           | Prediction of node: 19.516\n",
      "|---------------- Split rule: Cost <= 109.3\n",
      "                   | MSE of the node: 6.13\n",
      "                   | Count of observations in node: 50\n",
      "                   | Prediction of node: 17.8\n",
      "|---------------- Split rule: Cost > 109.3\n",
      "                   | MSE of the node: 13.03\n",
      "                   | Count of observations in node: 19\n",
      "                   | Prediction of node: 24.032\n"
     ]
    }
   ],
   "source": [
    "\n",
    "root.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02de33bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./EPL_Soccer_MLR_LR.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "df.dropna(axis=0, how='all', thresh=None, subset=None, inplace=True)\n",
    "\n",
    "#dropping categorical columns\n",
    "new_df = df.select_dtypes(['number'])\n",
    "\n",
    "# The last column (Score) is our dependent variable\n",
    "X = new_df.iloc[:,:-1]\n",
    "y = new_df.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, seed=42)\n",
    "\n",
    "correlated_features = set()\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.8:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_features.add(colname)\n",
    "            \n",
    "X_train.drop(columns=correlated_features, axis=1, inplace=True)\n",
    "X_test.drop(columns=correlated_features, axis=1, inplace=True)\n",
    "X.drop(columns=correlated_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3ceb47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.46196735, 0.74246175, 0.87827764, 0.73471287, 0.82410885])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "#X, y = load_diabetes(return_X_y=True)\n",
    "regressor = DecisionTreeRegressor(random_state=0)\n",
    "cross_val_score(regressor, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d45b7eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model :  0.728305692\n"
     ]
    }
   ],
   "source": [
    "acc = [0.46196735, 0.74246175, 0.87827764, 0.73471287, 0.82410885]\n",
    "\n",
    "print(\"Accuracy of model : \", np.mean(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "941bd052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DistanceCovered(InKms)</th>\n",
       "      <th>Goals</th>\n",
       "      <th>AgentCharges</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Cost</th>\n",
       "      <th>PreviousClubCost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4.66</td>\n",
       "      <td>6.4</td>\n",
       "      <td>109.0</td>\n",
       "      <td>18.37</td>\n",
       "      <td>38.2</td>\n",
       "      <td>41.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.36</td>\n",
       "      <td>5.8</td>\n",
       "      <td>29.0</td>\n",
       "      <td>21.86</td>\n",
       "      <td>99.9</td>\n",
       "      <td>56.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4.87</td>\n",
       "      <td>6.4</td>\n",
       "      <td>64.0</td>\n",
       "      <td>20.17</td>\n",
       "      <td>99.8</td>\n",
       "      <td>52.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>5.48</td>\n",
       "      <td>4.6</td>\n",
       "      <td>132.0</td>\n",
       "      <td>32.52</td>\n",
       "      <td>55.7</td>\n",
       "      <td>102.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>5.29</td>\n",
       "      <td>12.7</td>\n",
       "      <td>124.0</td>\n",
       "      <td>23.38</td>\n",
       "      <td>75.9</td>\n",
       "      <td>74.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>5.59</td>\n",
       "      <td>7.9</td>\n",
       "      <td>220.0</td>\n",
       "      <td>23.55</td>\n",
       "      <td>41.9</td>\n",
       "      <td>63.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>5.00</td>\n",
       "      <td>6.7</td>\n",
       "      <td>72.0</td>\n",
       "      <td>24.64</td>\n",
       "      <td>49.6</td>\n",
       "      <td>79.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.51</td>\n",
       "      <td>8.3</td>\n",
       "      <td>34.0</td>\n",
       "      <td>21.27</td>\n",
       "      <td>69.9</td>\n",
       "      <td>56.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>4.77</td>\n",
       "      <td>7.1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>26.85</td>\n",
       "      <td>103.6</td>\n",
       "      <td>66.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>4.96</td>\n",
       "      <td>8.3</td>\n",
       "      <td>141.0</td>\n",
       "      <td>33.73</td>\n",
       "      <td>113.5</td>\n",
       "      <td>89.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DistanceCovered(InKms)  Goals  AgentCharges    BMI   Cost  \\\n",
       "95                     4.66    6.4         109.0  18.37   38.2   \n",
       "15                     4.36    5.8          29.0  21.86   99.9   \n",
       "30                     4.87    6.4          64.0  20.17   99.8   \n",
       "159                    5.48    4.6         132.0  32.52   55.7   \n",
       "186                    5.29   12.7         124.0  23.38   75.9   \n",
       "..                      ...    ...           ...    ...    ...   \n",
       "173                    5.59    7.9         220.0  23.55   41.9   \n",
       "131                    5.00    6.7          72.0  24.64   49.6   \n",
       "17                     4.51    8.3          34.0  21.27   69.9   \n",
       "72                     4.77    7.1          40.0  26.85  103.6   \n",
       "177                    4.96    8.3         141.0  33.73  113.5   \n",
       "\n",
       "     PreviousClubCost  \n",
       "95              41.93  \n",
       "15              56.52  \n",
       "30              52.72  \n",
       "159            102.00  \n",
       "186             74.00  \n",
       "..                ...  \n",
       "173             63.00  \n",
       "131             79.00  \n",
       "17              56.31  \n",
       "72              66.85  \n",
       "177             89.00  \n",
       "\n",
       "[162 rows x 6 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d3ee7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost < 44.65, 45 nodes, 7.39 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "edc69b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "fil_df = new_df[new_df[\"Cost\"]<=44.65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "680ad9f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 11)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "02d59584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.292777777777779"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(fil_df[\"Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feefbf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
