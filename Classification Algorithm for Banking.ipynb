{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74Yfe5HhJwVc"
   },
   "source": [
    "# Classification Algorithm for Banking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lcfDcE3hJwVi"
   },
   "outputs": [],
   "source": [
    "#Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lHVEbWyO8VKG"
   },
   "outputs": [],
   "source": [
    "# To enable plotting graphs in Jupyter notebook\n",
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/Data1.csv', 'data/Data2.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "import urllib.request\n",
    "from io import BytesIO\n",
    "folder = urllib.request.urlopen('https://s3.amazonaws.com/projex.dezyre.com/classification-algorithms-for-digital-transformation-in-banking/materials/data.zip')\n",
    "zipfile = ZipFile(BytesIO(folder.read()))\n",
    "zipfile.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eqL3DKFOJwVj"
   },
   "outputs": [],
   "source": [
    "# Load customer data present in CSV file\n",
    "data1 = pd.read_csv(zipfile.open(\"data/Data1.csv\"))\n",
    "data2 = pd.read_csv(zipfile.open(\"data/Data2.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mac-N-hhJwVj",
    "outputId": "1c4c8ec8-1785-453c-f31e-50b3a2a8aeb2"
   },
   "outputs": [],
   "source": [
    "# Shape and size of data\n",
    "print(data1.shape)\n",
    "print(data2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X4JyjdChJwVl"
   },
   "outputs": [],
   "source": [
    "# Merging two data frames. Use Pandas merge function to merge two data frames based on cutomer ID\n",
    "cust_data=data1.merge(data2, how='inner', on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nhnULTa8JwVl",
    "outputId": "a926a752-c785-4d42-cdba-6b7a6812b27f"
   },
   "outputs": [],
   "source": [
    "# Explore final shape of data\n",
    "print(cust_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kp7hM01yJwVm",
    "outputId": "7fa5d96f-a710-41c9-f9fe-498cf484da15"
   },
   "outputs": [],
   "source": [
    "# Explore data types\n",
    "cust_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYwJI3djJwVn"
   },
   "source": [
    "### Comment: As all data attributes are quantitative data, we don't need data transformation here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VWjc4mc7JwVn",
    "outputId": "11ddc213-f0c6-4c46-d3dd-775638dc43f7"
   },
   "outputs": [],
   "source": [
    "# Data description\n",
    "cust_data.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l-eqEcpaJwVo"
   },
   "outputs": [],
   "source": [
    "# Dropping ID as it doesn't have any impact on learning\n",
    "cust_data = cust_data.drop(columns='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "alE6I5OXJwVp",
    "outputId": "6a50e3d4-0f79-4867-f600-05297d1d1846"
   },
   "outputs": [],
   "source": [
    "cust_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8w2p7kCPJwVp",
    "outputId": "f2ba7844-551d-45d2-a955-9125cb4ba8cd"
   },
   "outputs": [],
   "source": [
    "# Check for null value\n",
    "cust_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3iXhfquJwVq"
   },
   "source": [
    "### Comment: LoanOnCard attribute has 20 null data, which is 0.4% only. Secondly, it is the target class hence we can't repplace null value using mean or mode. We can remove these data from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AA2b4ioJJwVq"
   },
   "outputs": [],
   "source": [
    "cust_data = cust_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WSd31bypJwVq",
    "outputId": "9b2b0425-e209-4bca-f9b0-f4359a555972"
   },
   "outputs": [],
   "source": [
    "cust_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xo-co7UXJwVr"
   },
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWfpkIF5JwVr",
    "outputId": "b2a4bb8a-87bb-4ec9-aa80-1835b9893b76"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x = 'LoanOnCard',  data = cust_data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "96UoYXQnJwVr"
   },
   "source": [
    "### Calculate target class data percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "niGWIQUjJwVs",
    "outputId": "033a7500-0a59-4646-e3c7-0026d1f0f124"
   },
   "outputs": [],
   "source": [
    "n_true = len(cust_data.loc[cust_data['LoanOnCard'] == 1.0])\n",
    "n_false = len(cust_data.loc[cust_data['LoanOnCard'] == 0.0])\n",
    "print(\"No. of true cases: {0} ({1:2.2f}%)\".format(n_true, (n_true / (n_true + n_false)) * 100 ))\n",
    "print(\"No. of false cases: {0} ({1:2.2f}%)\".format(n_false, (n_false / (n_true + n_false)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPjsOVXTJwVs"
   },
   "source": [
    "## Comment: Data imbalance is a typical problem in machine learning. Later we shall use it's impact when we develop ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8-2JyMwBJwVs",
    "outputId": "d128ef40-9590-4f75-9292-653cd4f97d35"
   },
   "outputs": [],
   "source": [
    "# Scatter plot to see how data points are distributed for \"MonthlyAverageSpend\" and \"HighestSpend\" as per target class\n",
    "g = sns.scatterplot(x=\"HighestSpend\", y=\"MonthlyAverageSpend\", hue=\"LoanOnCard\",\n",
    "             data=cust_data,legend='full')\n",
    "g.set(xscale=\"log\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YJBGJ8tTJwVs",
    "outputId": "46424ac9-e7d2-418b-c54b-85288dc7e39d"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "sns.histplot(cust_data.loc[cust_data.LoanOnCard == 0.0, 'Mortgage'], ax = ax[0])\n",
    "sns.histplot(cust_data.loc[cust_data.LoanOnCard == 1.0, 'Mortgage'], ax = ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nQaI3QOyJwVt",
    "outputId": "fe739965-0ed3-44b5-b7ce-517409673cc0"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "sns.histplot(cust_data.loc[cust_data.LoanOnCard == 0.0, 'FixedDepositAccount'], ax = ax[0])\n",
    "sns.histplot(cust_data.loc[cust_data.LoanOnCard == 1.0, 'FixedDepositAccount'], ax = ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v9IrMwpAJwVt",
    "outputId": "1e3bbcfa-a632-4873-f0c7-d23deb987ab2"
   },
   "outputs": [],
   "source": [
    "columns = list(cust_data)[0:-1] # Excluding Outcome column which has only \n",
    "cust_data[columns].hist(stacked=False, bins=100, figsize=(12,30), layout=(14,2)); \n",
    "# Histogram of first 8 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MGHO2Q6wJwVu",
    "outputId": "b0f2f738-2616-4c66-9aba-c54ec20dd8f6"
   },
   "outputs": [],
   "source": [
    "sns.pairplot(cust_data, height=3, hue = 'LoanOnCard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFfwVh2eJwVu"
   },
   "source": [
    "### Zipcode doesn't have any significance with other dependant variables and on learning, hence drop it from dependant variable list.\n",
    "\n",
    "### Age and customer Since have similar information content. Will verify through correlation analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vuj1Loh6JwVu"
   },
   "outputs": [],
   "source": [
    "cust_data = cust_data.drop(columns='ZipCode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tWk1lbPEJwVu",
    "outputId": "3c2effbb-41d5-4211-b6f7-4ed4b3cd1cbf"
   },
   "outputs": [],
   "source": [
    "#Correlation analysis\n",
    "corr = cust_data.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4yIBne1vJwVu",
    "outputId": "cc4577ac-0a44-446b-d6ab-f44fd21f4de8"
   },
   "outputs": [],
   "source": [
    "#heatmap\n",
    "fig,ax = plt.subplots(figsize=(10, 10))   \n",
    "sns.heatmap(cust_data.corr(), ax=ax, annot=True, linewidths=0.05, fmt= '.2f',cmap=\"magma\") # the color intensity is based on \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5oZ_7MxbJwVv"
   },
   "outputs": [],
   "source": [
    "cust_data = cust_data.drop(columns='Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PEiF-jJJJwVv",
    "outputId": "b28edbc3-0c5c-4ab2-a487-e929d9bdebf8"
   },
   "outputs": [],
   "source": [
    "cust_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EEJgZYrGJwVv",
    "outputId": "dcb19d37-8dc1-4a36-c89d-1737d55b2ea7"
   },
   "outputs": [],
   "source": [
    "cust_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZEnfmnl_JwVv",
    "outputId": "a2e95a12-5d7a-4198-ed40-2e0a46be32ff"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = cust_data.drop('LoanOnCard',axis=1)     # Predictor feature columns (8 X m)\n",
    "Y = cust_data['LoanOnCard']   # Predicted class (1=True, 0=False) (1 X m)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=1)\n",
    "# 1 is just any random seed number\n",
    "\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlfoundry in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (0.4.8)\n",
      "Requirement already satisfied: fastparquet<0.8.0,>=0.7.2 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from mlfoundry) (0.7.2)\n",
      "Requirement already satisfied: pydantic<2.0.0,>=1.8.2 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from mlfoundry) (1.10.2)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.17.0 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from mlfoundry) (1.21.5)\n",
      "Requirement already satisfied: pandas<2.0.0,>=1.0.0 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from mlfoundry) (1.4.2)\n",
      "Requirement already satisfied: packaging<22.0,>=21.3 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from mlfoundry) (21.3)\n",
      "Requirement already satisfied: tfy-mlflow-client==0.0.17 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from mlfoundry) (0.0.17)\n",
      "Requirement already satisfied: GitPython<4.0.0,>=3.1.26 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from mlfoundry) (3.1.28)\n",
      "Requirement already satisfied: whylogs<0.7.0,>=0.6.15 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from mlfoundry) (0.6.30)\n",
      "Requirement already satisfied: amplitude-tracker<0.0.8,>=0.0.7 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from mlfoundry) (0.0.7)\n",
      "Requirement already satisfied: psutil<6.0.0,>=5.9.0 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from mlfoundry) (5.9.2)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.5.4 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from mlfoundry) (1.7.3)\n",
      "Requirement already satisfied: tinynetrc<2.0.0,>=1.3.1 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from mlfoundry) (1.3.1)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.14.1 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from mlfoundry) (1.21.32)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=0.24.2 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from mlfoundry) (1.1.2)\n",
      "Requirement already satisfied: coolname<2.0.0,>=1.1.0 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from mlfoundry) (1.1.0)\n",
      "Requirement already satisfied: pyarrow<9.0.0,>=5.0.0 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from mlfoundry) (8.0.0)\n",
      "Requirement already satisfied: importlib-metadata<5.0.0,>=4.11.3 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from mlfoundry) (4.11.3)\n",
      "Requirement already satisfied: databricks-cli>=0.8.7 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from tfy-mlflow-client==0.0.17->mlfoundry) (0.17.3)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from tfy-mlflow-client==0.0.17->mlfoundry) (2.0.0)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from tfy-mlflow-client==0.0.17->mlfoundry) (0.4)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from tfy-mlflow-client==0.0.17->mlfoundry) (3.19.1)\n",
      "Requirement already satisfied: requests>=2.17.3 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from tfy-mlflow-client==0.0.17->mlfoundry) (2.27.1)\n",
      "Requirement already satisfied: pytz in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from tfy-mlflow-client==0.0.17->mlfoundry) (2021.3)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from tfy-mlflow-client==0.0.17->mlfoundry) (8.0.4)\n",
      "Requirement already satisfied: sqlparse>=0.3.1 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from tfy-mlflow-client==0.0.17->mlfoundry) (0.4.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from tfy-mlflow-client==0.0.17->mlfoundry) (6.0)\n",
      "Requirement already satisfied: python-dateutil>2.1 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from amplitude-tracker<0.0.8,>=0.0.7->mlfoundry) (2.8.2)\n",
      "Requirement already satisfied: backoff==1.10.0 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from amplitude-tracker<0.0.8,>=0.0.7->mlfoundry) (1.10.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from amplitude-tracker<0.0.8,>=0.0.7->mlfoundry) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from amplitude-tracker<0.0.8,>=0.0.7->mlfoundry) (1.6)\n",
      "Requirement already satisfied: botocore<1.25.0,>=1.24.32 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from boto3<2.0.0,>=1.14.1->mlfoundry) (1.24.32)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from boto3<2.0.0,>=1.14.1->mlfoundry) (0.5.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from boto3<2.0.0,>=1.14.1->mlfoundry) (0.10.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from botocore<1.25.0,>=1.24.32->boto3<2.0.0,>=1.14.1->mlfoundry) (1.26.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from click>=7.0->tfy-mlflow-client==0.0.17->mlfoundry) (0.4.4)\n",
      "Requirement already satisfied: oauthlib>=3.1.0 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from databricks-cli>=0.8.7->tfy-mlflow-client==0.0.17->mlfoundry) (3.2.0)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from databricks-cli>=0.8.7->tfy-mlflow-client==0.0.17->mlfoundry) (0.8.9)\n",
      "Requirement already satisfied: pyjwt>=1.7.0 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from databricks-cli>=0.8.7->tfy-mlflow-client==0.0.17->mlfoundry) (2.1.0)\n",
      "Requirement already satisfied: thrift>=0.11.0 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from fastparquet<0.8.0,>=0.7.2->mlfoundry) (0.16.0)\n",
      "Requirement already satisfied: cramjam>=2.3.0 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from fastparquet<0.8.0,>=0.7.2->mlfoundry) (2.5.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from fastparquet<0.8.0,>=0.7.2->mlfoundry) (2022.2.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from GitPython<4.0.0,>=3.1.26->mlfoundry) (4.0.9)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython<4.0.0,>=3.1.26->mlfoundry) (5.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from importlib-metadata<5.0.0,>=4.11.3->mlfoundry) (3.7.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from packaging<22.0,>=21.3->mlfoundry) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from pydantic<2.0.0,>=1.8.2->mlfoundry) (4.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from requests>=2.17.3->tfy-mlflow-client==0.0.17->mlfoundry) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from requests>=2.17.3->tfy-mlflow-client==0.0.17->mlfoundry) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from requests>=2.17.3->tfy-mlflow-client==0.0.17->mlfoundry) (2022.9.24)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from scikit-learn<2.0.0,>=0.24.2->mlfoundry) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from scikit-learn<2.0.0,>=0.24.2->mlfoundry) (1.1.0)\n",
      "Requirement already satisfied: puremagic<2.0,>=1.10 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from whylogs<0.7.0,>=0.6.15->mlfoundry) (1.14)\n",
      "Requirement already satisfied: smart-open>=4.1.2 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from whylogs<0.7.0,>=0.6.15->mlfoundry) (5.1.0)\n",
      "Requirement already satisfied: whylabs-datasketches>=2.2.0b1 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from whylogs<0.7.0,>=0.6.15->mlfoundry) (2.2.0b1)\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.0.3 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from whylogs<0.7.0,>=0.6.15->mlfoundry) (3.5.1)\n",
      "Requirement already satisfied: whylabs-client<0.4.0,>=0.3.0 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from whylogs<0.7.0,>=0.6.15->mlfoundry) (0.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.60.0 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from whylogs<0.7.0,>=0.6.15->mlfoundry) (4.64.0)\n",
      "Requirement already satisfied: jsonschema>=3.2.0 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from whylogs<0.7.0,>=0.6.15->mlfoundry) (4.4.0)\n",
      "Requirement already satisfied: marshmallow>=3.7.1 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from whylogs<0.7.0,>=0.6.15->mlfoundry) (3.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from jsonschema>=3.2.0->whylogs<0.7.0,>=0.6.15->mlfoundry) (21.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from jsonschema>=3.2.0->whylogs<0.7.0,>=0.6.15->mlfoundry) (0.18.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.3->whylogs<0.7.0,>=0.6.15->mlfoundry) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.3->whylogs<0.7.0,>=0.6.15->mlfoundry) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.3->whylogs<0.7.0,>=0.6.15->mlfoundry) (4.25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\ranbi\\anaconda3\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.3->whylogs<0.7.0,>=0.6.15->mlfoundry) (9.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install mlfoundry --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please get your API key from https://projectpro.truefoundry.com/settings\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import mlfoundry as mlf\n",
    "\n",
    "TRACKING_URL = 'https://projectpro.truefoundry.com'\n",
    "mlf_api = mlf.get_client(TRACKING_URL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7xeqGOxJwVv"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pw-BiGn_JwVv",
    "outputId": "0b9d3163-283b-41c6-9e07-3dc820b9299a"
   },
   "outputs": [],
   "source": [
    "# import model and matrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, precision_score, recall_score, f1_score, roc_curve\n",
    "from sklearn import metrics\n",
    "# Fit the model on train\n",
    "model = LogisticRegression(solver=\"liblinear\")\n",
    "model.fit(x_train, y_train)\n",
    "#predict on test\n",
    "y_predict = model.predict(x_test)\n",
    "coef_df = pd.DataFrame(model.coef_)\n",
    "coef_df['intercept'] = model.intercept_\n",
    "print(coef_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ZYZnX8YJwVv",
    "outputId": "0a02eba1-1757-4b76-f004-4077b2cffd6e"
   },
   "outputs": [],
   "source": [
    "model_score = model.score(x_test, y_test)\n",
    "print(model_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YrRhG_wsJwVw",
    "outputId": "829af6b4-3ade-4760-ebf3-310370f73a25"
   },
   "outputs": [],
   "source": [
    "# performance\n",
    "print(f'Accuracy Score: {accuracy_score(y_test,y_predict)}')\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(y_test, y_predict)}')\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_predict)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_predict)}')\n",
    "print(f'Precision score: {precision_score(y_test,y_predict)}')\n",
    "print(f'f1 score: {f1_score(y_test,y_predict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf_run = mlf_api.create_run(project_name='digital-transformation-in-banking', run_name=\"logistic-reg-model\")\n",
    "\n",
    "metrics_dict = {\n",
    "    \"accuracy\": accuracy_score(y_test,y_predict),\n",
    "    \"auc\": roc_auc_score(y_test, y_predict),\n",
    "    \"precision-score\": recall_score(y_test,y_predict),\n",
    "    \"recall-score\": precision_score(y_test,y_predict),\n",
    "    \"f1-score\": f1_score(y_test,y_predict)\n",
    "}\n",
    "\n",
    "mlf_run.log_metrics(metrics_dict)\n",
    "mlf_run.log_params(model.get_params())\n",
    "mlf_run.log_model(model, framework=mlf.ModelFramework.SKLEARN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = confusion_matrix(y_test, y_predict)\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=mat)\n",
    "disp.plot()\n",
    "mlf_run.log_plots({\"confusion-matrix\": plt}, step=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yproba = model.predict_proba(x_test)[::,1]\n",
    "fpr, tpr, _ = roc_curve(y_test,  yproba)\n",
    "plt.plot(fpr, tpr, label=f\"ROC curve\")\n",
    "mlf_run.log_plots({\"ROC-curve\": plt}, step=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf_run.log_dataset(\n",
    "    dataset_name = 'test_dataset',\n",
    "    features = x_test,\n",
    "    predictions = y_predict,\n",
    "    actuals = y_test,\n",
    "    only_stats = False,   \n",
    ")\n",
    "mlf_run.end()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gURKKKMKJwVw"
   },
   "source": [
    "## Weighted Logistic Regression to handle class inbalance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cQYb9zLhJwVw"
   },
   "outputs": [],
   "source": [
    "# define class weights\n",
    "w = {0:1, 1:2}\n",
    "\n",
    "# Fit the model on train\n",
    "model_weighted = LogisticRegression(solver=\"liblinear\", class_weight=w)\n",
    "model_weighted.fit(x_train, y_train)\n",
    "#predict on test\n",
    "y_predict = model_weighted.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KTcbwJelJwVw",
    "outputId": "b0d3c37d-20bc-4d4b-9745-c7da9eb31cb2"
   },
   "outputs": [],
   "source": [
    "print(f'Accuracy Score: {accuracy_score(y_test,y_predict)}')\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(y_test, y_predict)}')\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_predict)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_predict)}')\n",
    "print(f'Precision score: {precision_score(y_test,y_predict)}')\n",
    "print(f'f1 score: {f1_score(y_test,y_predict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf_run = mlf_api.create_run(project_name='digital-transformation-in-banking', run_name=\"logistic-reg-model-with-class-weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = {\n",
    "    \"accuracy\": accuracy_score(y_test,y_predict),\n",
    "    \"auc\": roc_auc_score(y_test, y_predict),\n",
    "    \"precision-score\": recall_score(y_test,y_predict),\n",
    "    \"recall-score\": precision_score(y_test,y_predict),\n",
    "    \"f1-score\": f1_score(y_test,y_predict)\n",
    "}\n",
    "mlf_run.log_metrics(metrics_dict)\n",
    "mlf_run.log_params(model_weighted.get_params())\n",
    "mlf_run.log_model(model_weighted, framework=mlf.ModelFramework.SKLEARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = confusion_matrix(y_test, y_predict)\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=mat)\n",
    "disp.plot()\n",
    "mlf_run.log_plots({\"confusion-matrix\": plt}, step=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yproba = model_weighted.predict_proba(x_test)[::,1]\n",
    "fpr, tpr, _ = roc_curve(y_test,  yproba)\n",
    "plt.plot(fpr, tpr, label=f\"ROC curve\")\n",
    "mlf_run.log_plots({\"ROC-curve\": plt}, step=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf_run.log_dataset(\n",
    "    dataset_name = 'test_dataset',\n",
    "    features = x_test,\n",
    "    predictions = y_predict,\n",
    "    actuals = y_test,\n",
    "    only_stats = False,   \n",
    ")\n",
    "\n",
    "mlf_run.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-5OM8suJwVw"
   },
   "source": [
    "### Although the accuracy decreases, AUC and recall increases significantly, hence, it is a better model. Hence we select \"model_weighted\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLfXQ5FiJwVw"
   },
   "source": [
    "## Train Naive bayes algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YqpFLcdeJwVw",
    "outputId": "bc72c68e-32f9-46c2-a708-f9e9de1540f9"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB # using Gaussian algorithm from Naive Bayes\n",
    "\n",
    "# create the model\n",
    "diab_model = GaussianNB()\n",
    "\n",
    "diab_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TuKRWSkrJwVw"
   },
   "source": [
    "### Performance with training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AIDm_5ljJwVx",
    "outputId": "bed3fb7e-039d-4c39-c474-d7c4bfb1c81b"
   },
   "outputs": [],
   "source": [
    "diab_train_predict = diab_model.predict(x_train)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"Model Accuracy: {0:.4f}\".format(metrics.accuracy_score(y_train, diab_train_predict)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMHHiO3jJwVx"
   },
   "source": [
    "### Performance with testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z1ShNZtVJwVx",
    "outputId": "be124fc3-7aa1-40ac-937c-278e27648d10"
   },
   "outputs": [],
   "source": [
    "y_predict = diab_model.predict(x_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"Model Accuracy: {0:.4f}\".format(metrics.accuracy_score(y_test, y_predict)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uIjiaE8HJwVx",
    "outputId": "6e7010de-829e-4636-89c9-5bca72e71844"
   },
   "outputs": [],
   "source": [
    "# performance\n",
    "print(f'Accuracy Score: {accuracy_score(y_test,y_predict)}')\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(y_test, y_predict)}')\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_predict)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_predict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf_run = mlf_api.create_run(project_name='digital-transformation-in-banking', run_name=\"naive-bayes\")\n",
    "\n",
    "metrics_dict = {\n",
    "    \"accuracy\": accuracy_score(y_test,y_predict),\n",
    "    \"auc\": roc_auc_score(y_test, y_predict),\n",
    "    \"precision-score\": recall_score(y_test,y_predict),\n",
    "    \"recall-score\": precision_score(y_test,y_predict),\n",
    "    \"f1-score\": f1_score(y_test,y_predict)\n",
    "}\n",
    "mlf_run.log_metrics(metrics_dict)\n",
    "mlf_run.log_params(diab_model.get_params())\n",
    "mlf_run.log_model(diab_model, framework=mlf.ModelFramework.SKLEARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = confusion_matrix(y_test, y_predict)\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=mat)\n",
    "disp.plot()\n",
    "mlf_run.log_plots({\"confusion-matrix\": plt}, step=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yproba = diab_model.predict_proba(x_test)[::,1]\n",
    "fpr, tpr, _ = roc_curve(y_test,  yproba)\n",
    "plt.plot(fpr, tpr, label=f\"ROC curve\")\n",
    "mlf_run.log_plots({\"ROC-curve\": plt}, step=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf_run.log_dataset(\n",
    "    dataset_name = 'test_dataset',\n",
    "    features = x_test,\n",
    "    predictions = y_predict,\n",
    "    actuals = y_test,\n",
    "    only_stats = False,   \n",
    ")\n",
    "mlf_run.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvAoOqS-JwVx"
   },
   "source": [
    "### Use of class prior for inbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rBtgrlHuJwVx"
   },
   "outputs": [],
   "source": [
    "diab_model_cp = GaussianNB(priors=[0.1, 0.9])\n",
    "#diab_model.class_prior_ = [0.9, 0.1]\n",
    "diab_model_cp.fit(x_train, y_train.ravel()) \n",
    "y_predict = diab_model_cp.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OwsfT3TNJwVx",
    "outputId": "998177e5-919b-4711-a900-2e5234888db3"
   },
   "outputs": [],
   "source": [
    "# performance\n",
    "print(f'Accuracy Score: {accuracy_score(y_test,y_predict)}')\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(y_test, y_predict)}')\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_predict)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_predict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf_run = mlf_api.create_run(project_name='digital-transformation-in-banking', run_name=\"naive-bayes-with-priors\")\n",
    "\n",
    "metrics_dict = {\n",
    "    \"accuracy\": accuracy_score(y_test,y_predict),\n",
    "    \"auc\": roc_auc_score(y_test, y_predict),\n",
    "    \"precision-score\": recall_score(y_test,y_predict),\n",
    "    \"recall-score\": precision_score(y_test,y_predict),\n",
    "    \"f1-score\": f1_score(y_test,y_predict)\n",
    "}\n",
    "mlf_run.log_metrics(metrics_dict)\n",
    "mlf_run.log_params(diab_model_cp.get_params())\n",
    "mlf_run.log_model(diab_model_cp, framework=mlf.ModelFramework.SKLEARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = confusion_matrix(y_test, y_predict)\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=mat)\n",
    "disp.plot()\n",
    "mlf_run.log_plots({\"confusion-matrix\": plt}, step=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yproba = diab_model_cp.predict_proba(x_test)[::,1]\n",
    "fpr, tpr, _ = roc_curve(y_test,  yproba)\n",
    "plt.plot(fpr, tpr, label=f\"ROC curve\")\n",
    "mlf_run.log_plots({\"ROC-curve\": plt}, step=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf_run.log_dataset(\n",
    "    dataset_name = 'test_dataset',\n",
    "    features = x_test,\n",
    "    predictions = y_predict,\n",
    "    actuals = y_test,\n",
    "    only_stats = False,\n",
    ")\n",
    "mlf_run.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HC3Yvv1vJwVx"
   },
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YU4xPHDCJwVy"
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(gamma=0.25, C=10)\n",
    "clf.fit(x_train , y_train)\n",
    "y_predict = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gtf58gavJwVy"
   },
   "outputs": [],
   "source": [
    "### gamma is a measure of influence of a data point. It is inverse of distance of influence. \n",
    "### C is penalty of wrong classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "THKXkB-cJwVy",
    "outputId": "e64ced36-4da1-49b3-b11d-1e799f53747d"
   },
   "outputs": [],
   "source": [
    "print(f'Accuracy Score: {accuracy_score(y_test,y_predict)}')\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(y_test, y_predict)}')\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_predict)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_predict)}')\n",
    "print(f'Precision score: {precision_score(y_test,y_predict)}')\n",
    "print(f'f1 score: {f1_score(y_test,y_predict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SFmxVCW4JwVy",
    "outputId": "aebddd8c-764c-4be2-e499-9dfcb4a0b845"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "XScaled  = X.apply(zscore)  # convert all attributes to Z scale \n",
    "XScaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "erpQ0Ys5JwVy"
   },
   "outputs": [],
   "source": [
    "x_trains, x_tests, y_trains, y_tests = train_test_split(XScaled, Y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uHO4-YejJwVy"
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(gamma=0.25, C=10, probability=True)\n",
    "clf.fit(x_trains , y_trains)\n",
    "y_predicts = clf.predict(x_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Zu1MX77JwVy",
    "outputId": "07e1f4ac-24ea-48ec-cf0e-0cf7e2deb24e"
   },
   "outputs": [],
   "source": [
    "print(f'Accuracy Score: {accuracy_score(y_tests,y_predicts)}')\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(y_tests, y_predicts)}')\n",
    "print(f'Area Under Curve: {roc_auc_score(y_tests, y_predicts)}')\n",
    "print(f'Recall score: {recall_score(y_tests,y_predicts)}')\n",
    "print(f'Precision score: {precision_score(y_tests,y_predicts)}')\n",
    "print(f'f1 score: {f1_score(y_tests,y_predicts)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf_run = mlf_api.create_run(project_name='digital-transformation-in-banking', run_name=\"svm\")\n",
    "\n",
    "metrics_dict = {\n",
    "    \"accuracy\": accuracy_score(y_test,y_predict),\n",
    "    \"auc\": roc_auc_score(y_test, y_predict),\n",
    "    \"precision-score\": recall_score(y_test,y_predict),\n",
    "    \"recall-score\": precision_score(y_test,y_predict),\n",
    "    \"f1-score\": f1_score(y_test,y_predict)\n",
    "}\n",
    "mlf_run.log_metrics(metrics_dict)\n",
    "mlf_run.log_params(clf.get_params())\n",
    "mlf_run.log_model(clf, framework=mlf.ModelFramework.SKLEARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = confusion_matrix(y_test, y_predict)\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=mat)\n",
    "disp.plot()\n",
    "mlf_run.log_plots({\"confusion-matrix\": plt}, step=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yproba = clf.predict_proba(x_test)[::,1]\n",
    "fpr, tpr, _ = roc_curve(y_test,  yproba)\n",
    "plt.plot(fpr, tpr, label=f\"ROC curve\")\n",
    "mlf_run.log_plots({\"ROC-curve\": plt}, step=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf_run.log_dataset(\n",
    "    dataset_name = 'test_dataset',\n",
    "    features = x_test,\n",
    "    predictions = y_predict,\n",
    "    actuals = y_test,\n",
    "    only_stats = False,   \n",
    ")\n",
    "mlf_run.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BBP4efMhJwVy"
   },
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ow8uebAGJwVy",
    "outputId": "6f5a7738-cd5e-4e34-ae02-a7825d8d852f"
   },
   "outputs": [],
   "source": [
    "# Build decision tree model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dTree = DecisionTreeClassifier(criterion = 'gini', random_state=1)\n",
    "dTree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K0x0xrNTJwVy",
    "outputId": "d110a6c9-5167-4c25-90ab-005a282d1d61"
   },
   "outputs": [],
   "source": [
    "# Scoring our DT\n",
    "print(dTree.score(x_train, y_train))\n",
    "print(dTree.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W_Lad05GJwVz",
    "outputId": "1a43b88b-cb84-4e49-f912-b67c79481370"
   },
   "outputs": [],
   "source": [
    "y_predict = dTree.predict(x_test)\n",
    "print(f'Accuracy Score: {accuracy_score(y_test,y_predict)}')\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(y_test, y_predict)}')\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_predict)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_predict)}')\n",
    "print(f'Precision score: {precision_score(y_test,y_predict)}')\n",
    "print(f'f1 score: {f1_score(y_test,y_predict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JG9Odcr2JwVz",
    "outputId": "5d82608c-4a4f-4115-9008-68702e1c23c4"
   },
   "outputs": [],
   "source": [
    "#Reducing over fitting (Regularization)\n",
    "dTreeR = DecisionTreeClassifier(criterion = 'gini', max_depth = 5, random_state=1)\n",
    "dTreeR.fit(x_train, y_train)\n",
    "print(dTreeR.score(x_train, y_train))\n",
    "print(dTreeR.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a07wKKE-JwVz",
    "outputId": "461d6f20-3630-4164-9d64-078306d3c9e5"
   },
   "outputs": [],
   "source": [
    "y_predictR = dTreeR.predict(x_test)\n",
    "print(f'Accuracy Score: {accuracy_score(y_test,y_predictR)}')\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(y_test, y_predictR)}')\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_predictR)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_predictR)}')\n",
    "print(f'Precision score: {precision_score(y_test,y_predictR)}')\n",
    "print(f'f1 score: {f1_score(y_test,y_predictR)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W8zIxTaCJwVz",
    "outputId": "8fbb06f7-98f5-4253-e182-6ce1386ce7f9"
   },
   "outputs": [],
   "source": [
    "# Decision Tree Visualize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "dTreeR3 = DecisionTreeClassifier(criterion = 'gini', max_depth = 3, random_state=1)\n",
    "dTreeR3.fit(x_train, y_train)\n",
    "fn = list(x_train)\n",
    "cn = ['0', '1']\n",
    "fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (4, 4), dpi=300)\n",
    "plot_tree(dTreeR3, feature_names = fn, class_names=cn, filled = True)\n",
    "\n",
    "fig.savefig('tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf_run = mlf_api.create_run(project_name='digital-transformation-in-banking', run_name=\"decision-tree\")\n",
    "\n",
    "metrics_dict = {\n",
    "    \"accuracy\": accuracy_score(y_test,y_predictR),\n",
    "    \"auc\": roc_auc_score(y_test, y_predictR),\n",
    "    \"precision-score\": recall_score(y_test,y_predictR),\n",
    "    \"recall-score\": precision_score(y_test,y_predictR),\n",
    "    \"f1-score\": f1_score(y_test,y_predictR)\n",
    "}\n",
    "mlf_run.log_metrics(metrics_dict)\n",
    "mlf_run.log_params(dTree.get_params())\n",
    "mlf_run.log_model(dTree, framework=mlf.ModelFramework.SKLEARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = confusion_matrix(y_test, y_predictR)\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=mat)\n",
    "disp.plot()\n",
    "mlf_run.log_plots({\"confusion-matrix\": plt}, step=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yproba = clf.predict_proba(x_test)[::,1]\n",
    "fpr, tpr, _ = roc_curve(y_test,  yproba)\n",
    "plt.plot(fpr, tpr, label=f\"ROC curve\")\n",
    "mlf_run.log_plots({\"ROC-curve\": plt}, step=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf_run.log_dataset(\n",
    "    dataset_name = 'test_dataset',\n",
    "    features = x_test,\n",
    "    predictions = y_predictR,\n",
    "    actuals = y_test,\n",
    "    only_stats = False,   \n",
    ")\n",
    "mlf_run.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMd15YDFJwVz"
   },
   "source": [
    "## Ensemble Learning: Random forest classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LjIwJkuEJwVz"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfcl = RandomForestClassifier(random_state=1)\n",
    "rfcl = rfcl.fit(x_train, y_train)\n",
    "y_predict = rfcl.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PaEwZXi-JwVz",
    "outputId": "d5894bdc-fc50-4c17-c3dc-23f8580701e1"
   },
   "outputs": [],
   "source": [
    "# performance\n",
    "print(f'Accuracy Score: {accuracy_score(y_test,y_predict)}')\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(y_test, y_predict)}')\n",
    "print(f'Area Under Curve: {roc_auc_score(y_test, y_predict)}')\n",
    "print(f'Recall score: {recall_score(y_test,y_predict)}')\n",
    "print(f'Precision score: {precision_score(y_test,y_predict)}')\n",
    "print(f'f1 score: {f1_score(y_test,y_predict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf_run = mlf_api.create_run(project_name='digital-transformation-in-banking', run_name=\"random-forest\")\n",
    "\n",
    "metrics_dict = {\n",
    "    \"accuracy\": accuracy_score(y_test,y_predict),\n",
    "    \"auc\": roc_auc_score(y_test, y_predict),\n",
    "    \"precision-score\": recall_score(y_test,y_predict),\n",
    "    \"recall-score\": precision_score(y_test,y_predict),\n",
    "    \"f1-score\": f1_score(y_test,y_predict)\n",
    "}\n",
    "mlf_run.log_metrics(metrics_dict)\n",
    "mlf_run.log_params(rfcl.get_params())\n",
    "mlf_run.log_model(rfcl, framework=mlf.ModelFramework.SKLEARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = confusion_matrix(y_test, y_predict)\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=mat)\n",
    "disp.plot()\n",
    "mlf_run.log_plots({\"confusion-matrix\": plt}, step=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yproba = rfcl.predict_proba(x_test)[::,1]\n",
    "fpr, tpr, _ = roc_curve(y_test,  yproba)\n",
    "plt.plot(fpr, tpr, label=f\"ROC curve\")\n",
    "mlf_run.log_plots({\"ROC-curve\": plt}, step=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlf_run.log_dataset(\n",
    "    dataset_name = 'test_dataset',\n",
    "    features = x_test,\n",
    "    predictions = y_predict,\n",
    "    actuals = y_test,\n",
    "    only_stats = False,   \n",
    ")\n",
    "mlf_run.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mIaLFatLJwVz"
   },
   "source": [
    "## Unbalanced Data Handelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OaXiIf5dJwVz",
    "outputId": "ebc86d4d-4c2e-41ea-b14c-5df3b78ea74d"
   },
   "outputs": [],
   "source": [
    "# Install imbalanced-learn if you have not used before\n",
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YOaTsGqKJwVz",
    "outputId": "6e1aed8d-3045-4987-e8c0-7420aedff255"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from collections import Counter\n",
    "# summarize class distribution\n",
    "counter = Counter(Y)\n",
    "print(counter)\n",
    "# define pipeline\n",
    "over = SMOTE(sampling_strategy=0.3,random_state=1) #sampling_strategy=0.1,random_state=1\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "steps = [ ('o', over),('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# transform the dataset\n",
    "Xb, Yb = pipeline.fit_resample(XScaled, Y)\n",
    "# summarize the new class distribution\n",
    "counter = Counter(Yb)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vGRToprVJwV0"
   },
   "outputs": [],
   "source": [
    "x_trainb, x_testb, y_trainb, y_testb = train_test_split(Xb, Yb, test_size=0.3, random_state=1)\n",
    "# 1 is just any random seed number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mkz4rNBdJwV0"
   },
   "source": [
    "## SVM with balanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yh-hHNZJJwV0"
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(gamma=0.25, C=10)\n",
    "clf.fit(x_trainb , y_trainb)\n",
    "y_predictb = clf.predict(x_testb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MGFfr2MVJwV0",
    "outputId": "fe630ae3-30b7-4586-8305-13eebbe8e89e"
   },
   "outputs": [],
   "source": [
    "# performance\n",
    "print(f'Accuracy Score: {accuracy_score(y_testb,y_predictb)}')\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(y_testb, y_predictb)}')\n",
    "print(f'Area Under Curve: {roc_auc_score(y_testb, y_predictb)}')\n",
    "print(f'Recall score: {recall_score(y_testb,y_predictb)}')\n",
    "print(f'Precision score: {precision_score(y_testb,y_predictb)}')\n",
    "print(f'f1 score: {f1_score(y_testb,y_predictb)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUnf-UUHJwV0"
   },
   "source": [
    "## Random Forest classifier with Balanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZFIl9EEhJwV0"
   },
   "outputs": [],
   "source": [
    "rfcl = RandomForestClassifier(random_state=1)\n",
    "rfcl = rfcl.fit(x_trainb, y_trainb)\n",
    "y_predict = rfcl.predict(x_testb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cVVELVyJJwV0",
    "outputId": "d961554a-b5ee-4720-bd93-6321679796ef"
   },
   "outputs": [],
   "source": [
    "# performance\n",
    "print(f'Accuracy Score: {accuracy_score(y_testb,y_predict)}')\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(y_testb, y_predict)}')\n",
    "print(f'Area Under Curve: {roc_auc_score(y_testb, y_predict)}')\n",
    "print(f'Recall score: {recall_score(y_testb,y_predict)}')\n",
    "print(f'Precision score: {precision_score(y_testb,y_predict)}')\n",
    "print(f'f1 score: {f1_score(y_testb,y_predict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOdFyAN4JwV0"
   },
   "source": [
    "### Chosing hyperparameter using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z6bfpedJJwV0",
    "outputId": "fb01097f-cf5a-4835-bae2-020266008283"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.25,0.01],'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "grid = GridSearchCV(svm.SVC(),param_grid,refit=True,verbose=2)\n",
    "grid.fit(x_trainb,y_trainb)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmvTPnLVJwV0"
   },
   "source": [
    "## Pickle the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tafiChriJwV0"
   },
   "outputs": [],
   "source": [
    "# Pickle model file\n",
    "import pickle\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(rfcl, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0U3EZ5hJwV1"
   },
   "source": [
    "## Load model from pickle file and use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7lgVhfmSJwV1",
    "outputId": "98c7c755-897e-4d46-aae0-76672d72823c"
   },
   "outputs": [],
   "source": [
    "# Checking the pickle model\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.predict(x_testb)\n",
    "# performance\n",
    "print(f'Accuracy Score: {accuracy_score(y_testb,result)}')\n",
    "print(f'Confusion Matrix: \\n{confusion_matrix(y_testb, result)}')\n",
    "print(f'Area Under Curve: {roc_auc_score(y_testb, result)}')\n",
    "print(f'Recall score: {recall_score(y_testb,result)}')\n",
    "print(f'Precision score: {precision_score(y_testb,result)}')\n",
    "print(f'f1 score: {f1_score(y_testb,result)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WsVtIy2JwV1"
   },
   "source": [
    "# Conclusion: \n",
    "### We have built  a model using logistic regression, Support vector machine and Random forest classifier. This data set is highly imbalance hence accuracy can't a good measure, Hence we have used precision, Recall, and AUC for determining better model. \n",
    "### We use class weight technique to handle un balanced data and observe that the model performance improved by considering class weight. \n",
    "### Scaling/data transformation plays a major role when we work on SVM. \n",
    "### We have also explored undersampling and oversampling technique like SMOTE to handle data imbalance.\n",
    "### Hyper parameter tuning using Grid Search\n",
    "### We have also seen how to systematically improve a model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AxbSFR9vJwV1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Y3iXhfquJwVq",
    "Xo-co7UXJwVr",
    "oHsBfAP8JwVr",
    "96UoYXQnJwVr",
    "TPjsOVXTJwVs",
    "tFfwVh2eJwVu",
    "6vBADqeyJwVu",
    "Ej4d0Q4eJwVv",
    "E7xeqGOxJwVv",
    "celHLHYaJwVw",
    "gURKKKMKJwVw",
    "q-5OM8suJwVw",
    "YLfXQ5FiJwVw",
    "TuKRWSkrJwVw",
    "iMHHiO3jJwVx",
    "zvAoOqS-JwVx",
    "HC3Yvv1vJwVx",
    "BBP4efMhJwVy",
    "lMd15YDFJwVz",
    "mIaLFatLJwVz",
    "Mkz4rNBdJwV0",
    "cUnf-UUHJwV0",
    "HOdFyAN4JwV0",
    "GmvTPnLVJwV0",
    "P0U3EZ5hJwV1"
   ],
   "name": "Digital transformation in Banking sector.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "9ef903084c5c52a4a91f9ef5ca044f687b322219c655fbb3a0754c14ca2b62b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
